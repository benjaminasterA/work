import streamlit as st  # ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œì‘ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
import os, time, base64, textwrap  # ì‹œìŠ¤í…œ ì œì–´, ì‹œê°„ ì¸¡ì •, ì¸ì½”ë”©, í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ë„êµ¬
import pandas as pd  # [ì¶”ê°€] í†µê³„ ë°ì´í„° ë¶„ì„ ë° í‘œ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from io import BytesIO  # ë©”ëª¨ë¦¬ ë‚´ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬ìš© ë²„í¼
from PIL import Image, ImageDraw, ImageFont  # ì´ë¯¸ì§€ ìƒì„± ë° í•œê¸€ í°íŠ¸ ë Œë”ë§
from gtts import gTTS  # í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜(TTS) ì—”ì§„
from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAI ëª¨ë¸ ë° ì„ë² ë”© ì—°ê²°
from langchain_community.document_loaders import PyPDFLoader  # PDF ë¬¸ì„œ ë¡œë”
from langchain_community.vectorstores import FAISS  # ë²¡í„° ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤
from langchain_text_splitters import RecursiveCharacterTextSplitter  # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
from langchain.tools import tool  # ì—ì´ì „íŠ¸ ì „ìš© ë„êµ¬ ì •ì˜ìš© ë°ì½”ë ˆì´í„°
from langchain.agents import AgentExecutor, create_openai_functions_agent  # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì—”ì§„
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ë„êµ¬
from langchain_community.callbacks.manager import get_openai_callback  # í† í°ëŸ‰ ë° ë¹„ìš© ì‹¤ì‹œê°„ ì¶”ì ê¸°
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜(.env) ë¡œë“œ ë„êµ¬

# API í‚¤ ë° í™˜ê²½ ì„¤ì • ë¡œë“œ
load_dotenv()

# --- [1. ìì› ìµœì í™”: ì‹±ê¸€í†¤ ëª¨ë¸ ë° ì„¸ì…˜ ì„¤ì •] ---
# ëª¨ë¸ ê°ì²´ë¥¼ ë§¤ë²ˆ ìƒì„±í•˜ì§€ ì•Šê³  ì„¸ì…˜ì— í•˜ë‚˜ë§Œ ë“±ë¡í•˜ì—¬ ê³µìœ  (í† í° ë° ë©”ëª¨ë¦¬ ì ˆì•½)
if "shared_llm" not in st.session_state:
    st.session_state.shared_llm = ChatOpenAI(model="gpt-4o", temperature=0)

if "messages" not in st.session_state: st.session_state.messages = []  # ëŒ€í™” ì´ë ¥ ì €ì¥ì†Œ
if "last_response" not in st.session_state: st.session_state.last_response = ""  # ìµœì‹  ë‹µë³€ ì €ì¥ì†Œ
if "stats_history" not in st.session_state: st.session_state.stats_history = []  # í†µê³„ ë¡œê·¸ ì €ì¥ì†Œ

DB_INDEX_PATH = "faiss_index_storage"  # ë²¡í„° DB ì €ì¥ ê²½ë¡œ

# --- [2. ì—ì´ì „íŠ¸ ë„êµ¬ ì •ì˜: ë°ì´í„° ì›ë¬¸ë§Œ ë°˜í™˜í•˜ì—¬ í† í° ìµœì†Œí™”] ---

@tool
def search_allergy_docs(query: str):
    """ë°˜ë ¤ë™ë¬¼ ì•Œë ˆë¥´ê¸° PDFì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ ì›ë¬¸ ë¬¸ë§¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        embeddings = OpenAIEmbeddings()
        if os.path.exists(DB_INDEX_PATH):
            vector_db = FAISS.load_local(DB_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)
        else:
            loader = PyPDFLoader("./data/ë°˜ë ¤ë™ë¬¼_ì•Œë ˆë¥´ê¸°_ì˜ˆë°©ê´€ë¦¬ìˆ˜ì¹™.pdf")
            docs = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=30))
            vector_db = FAISS.from_documents(docs, embeddings)
            vector_db.save_local(DB_INDEX_PATH)
        
        # ì—ì´ì „íŠ¸ê°€ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ê²€ìƒ‰ëœ ì›ë¬¸ 2ê°œë§Œ ì „ë‹¬ (í† í° ì ˆì•½)
        results = vector_db.similarity_search(query, k=2)
        return "\n".join([f"[ì¶œì²˜:{d.metadata.get('page')}p] {d.page_content}" for d in results])
    except Exception as e:
        return f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"

@tool
def fetch_diabetes_raw(dummy: str = ""):
    """ë‹¹ë‡¨ë³‘ ì§„ë£Œì§€ì¹¨ì„œì˜ í•µì‹¬ ìš”ì•½ìš© ì›ë¬¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        loader = PyPDFLoader("./data/2025_ë‹¹ë‡¨ë³‘_ì§„ë£Œì§€ì¹¨.pdf")
        pages = loader.load()
        # ì „ì²´ê°€ ì•„ë‹Œ í•µì‹¬ ë‚´ìš©ì´ ìˆëŠ” ì•ë¶€ë¶„ 3í˜ì´ì§€ë§Œ ì „ì†¡í•˜ì—¬ ë¹„ìš© ì ˆê°
        return " ".join([p.page_content for p in pages[:3]])
    except Exception as e:
        return f"ì§€ì¹¨ì„œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

tools = [search_allergy_docs, fetch_diabetes_raw]

# --- [3. ì‹œê°í™” ë³´ì¡°: ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜] ---
def create_report_image(text):
    """ë‹µë³€ ë‚´ìš©ì„ í•œê¸€ ê¹¨ì§ ì—†ì´ PNG ì´ë¯¸ì§€ ë¦¬í¬íŠ¸ë¡œ ë³€í™˜"""
    img = Image.new('RGB', (800, 800), color=(255, 255, 255))
    draw = ImageDraw.Draw(img)
    # í•œê¸€ í°íŠ¸ ì„¤ì • (í™˜ê²½ì— ë”°ë¼ ìë™ íƒìƒ‰)
    fpath = "C:/Windows/Fonts/malgun.ttf" if os.name == 'nt' else "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
    try:
        font = ImageFont.truetype(fpath, 20); t_font = ImageFont.truetype(fpath, 30)
    except:
        font = ImageFont.load_default(); t_font = font

    draw.text((40, 40), "ğŸ“‹ AI ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸", font=t_font, fill=(0,0,0))
    y = 100
    for line in textwrap.wrap(text, width=42): # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
        draw.text((40, y), line, font=font, fill=(64,64,64))
        y += 30
    
    buf = BytesIO(); img.save(buf, format="PNG"); buf.seek(0)
    return buf.getvalue()

# --- [4. ë©”ì¸ UI ë° ì—ì´ì „íŠ¸ êµ¬ë™] ---
st.set_page_config(page_title="Expert Agent Admin", layout="wide")

# ì‚¬ì´ë“œë°” ê´€ë¦¬ ë©”ë‰´
with st.sidebar:
    st.header("ğŸ›ï¸ ì—ì´ì „íŠ¸ ì„¤ì •")
    menu = st.selectbox("ê¸°ëŠ¥ ì „í™˜", ["ğŸ’¬ ì „ë¬¸ê°€ ìƒë‹´ì‹¤", "ğŸ“Š ìš´ì˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"])
    st.divider()
    if st.button("ğŸ—‘ï¸ ëª¨ë“  ë¡œê·¸ ì´ˆê¸°í™”"):
        st.session_state.messages = []; st.session_state.stats_history = []; st.rerun()

# ì—ì´ì „íŠ¸ ê³µí†µ ì„¤ì • (ì‹±ê¸€ ëª¨ë¸ í™œìš©)
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ë„êµ¬ê°€ ì œê³µí•œ íŒ©íŠ¸ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ìœ„ì›ì…ë‹ˆë‹¤."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])
agent_engine = create_openai_functions_agent(st.session_state.shared_llm, tools, prompt_template)
agent_executor = AgentExecutor(agent=agent_engine, tools=tools, verbose=True)

# ë©”ë‰´ 1: ìƒë‹´ ì„œë¹„ìŠ¤
if menu == "ğŸ’¬ ì „ë¬¸ê°€ ìƒë‹´ì‹¤":
    st.title("ğŸ‘¨â€âš•ï¸ í†µí•© AI ì „ë¬¸ ì—ì´ì „íŠ¸")
    
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.write(msg["content"])

    if user_query := st.chat_input("ë¬¸ì˜ ì‚¬í•­ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": user_query})
        with st.chat_message("user"): st.write(user_query)

        with st.chat_message("assistant"):
            # ë‹¨ì¼ ëª¨ë¸ ì‹¤í–‰ ì‹œ í† í° ì†Œëª¨ëŸ‰ ì‹¤ì‹œê°„ ìº¡ì²˜
            with get_openai_callback() as cb:
                start_time = time.time()
                # ë¬¸ë§¥ ìµœì í™”: ìµœê·¼ ëŒ€í™” 3ê°œë§Œ ìœ ì§€í•˜ì—¬ ì…ë ¥ í† í° ì ˆì•½
                response = agent_executor.invoke({"input": user_query, "chat_history": st.session_state.messages[-3:]})
                ans = response["output"]
                latency = round(time.time() - start_time, 2)
                
                st.write(ans)
                st.session_state.last_response = ans
                st.session_state.messages.append({"role": "assistant", "content": ans})
                
                # í†µê³„ ë¡œê·¸ ê¸°ë¡
                st.session_state.stats_history.append({
                    "ì‹œê°„": time.strftime("%H:%M:%S"),
                    "ì†ë„": latency,
                    "í† í°": cb.total_tokens,
                    "ë¹„ìš©": cb.total_cost
                })

    # í•˜ë‹¨ ìœ í‹¸ë¦¬í‹° ì„¹ì…˜
    if st.session_state.last_response:
        st.divider()
        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸ”Š ìŒì„± ë¸Œë¦¬í•‘"):
                tts = gTTS(text=st.session_state.last_response, lang='ko')
                fp = BytesIO(); tts.write_to_fp(fp); fp.seek(0)
                st.audio(fp, format="audio/mp3")
        with c2:
            img_data = create_report_image(st.session_state.last_response)
            st.download_button("ğŸ“¸ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (PNG)", img_data, "ai_report.png", "image/png", key="down_btn")

# ë©”ë‰´ 2: ê°•í™”ëœ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
elif menu == "ğŸ“Š ìš´ì˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ":
    st.title("ğŸ“ˆ ì‹œìŠ¤í…œ ìš´ì˜ ì§€í‘œ ë¶„ì„")
    
    if not st.session_state.stats_history:
        st.info("ì•„ì§ ëŒ€í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒë‹´ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")
    else:
        df = pd.DataFrame(st.session_state.stats_history)

        # [ìš”ì²­ì‚¬í•­ ë°˜ì˜] ìƒë‹¨ ì§€í‘œ ì˜ì—­ (KPI Metrics)
        c1, c2, c3 = st.columns(3)
        c1.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{df['ì†ë„'].mean():.2f}ì´ˆ", delta=f"{df['ì†ë„'].iloc[-1] - df['ì†ë„'].mean():.2f}s", delta_color="inverse")
        c2.metric("ëˆ„ì  í† í° ì†Œëª¨", f"{df['í† í°'].sum():,} tokens")
        c3.metric("ëˆ„ì  ìš´ì˜ ë¹„ìš©", f"${df['ë¹„ìš©'].sum():.5f}")

        st.divider()

        # [ì‹œê°í™” ê°•í™”] ì²˜ë¦¬ ì†ë„ ë° í† í° ì†Œëª¨ëŸ‰ ê·¸ë˜í”„
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.subheader("â±ï¸ ì‘ë‹µ ì‹œê°„ ì¶”ì´ (Latency)")
            st.line_chart(df.set_index("ì‹œê°„")["ì†ë„"])
            st.caption("ì§ˆë¬¸ë³„ ì†Œìš” ì‹œê°„ì˜ ë³€í™”ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")

        with col_right:
            st.subheader("ğŸª™ í† í° ì‚¬ìš© íš¨ìœ¨ì„±")
            st.bar_chart(df.set_index("ì‹œê°„")["í† í°"])
            st.caption("ìš”ì²­ë‹¹ ì†Œëª¨ëœ í† í°ëŸ‰ì„ ë¹„êµí•©ë‹ˆë‹¤.")

        # [ìš”ì²­ì‚¬í•­ ë°˜ì˜] ìƒì„¸ ì„¸ì…˜ ë¡œê·¸ ë¦¬í¬íŠ¸ í…Œì´ë¸”
        st.subheader("ğŸ“ ìƒì„¸ ì„¸ì…˜ ì‹¤í–‰ ë¡œê·¸")
        st.dataframe(df, use_container_width=True)
        
        # ë¹„ìš© ìš”ì•½ ì¹´ë“œ
        st.info(f"ğŸ’¡ í˜„ì¬ê¹Œì§€ ì´ {len(df)}ê±´ì˜ ìš”ì²­ì„ ì²˜ë¦¬í–ˆìœ¼ë©°, í‰ê·  ë¹„ìš©ì€ ìš”ì²­ë‹¹ ${df['ë¹„ìš©'].mean():.6f} ì…ë‹ˆë‹¤.")